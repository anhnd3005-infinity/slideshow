# üé¨ Master Architecture Document - Video Editor Ki·ªÉu CapCut

## üìö T·ªïng Quan Documents

1. **[ARCHITECTURE_CAPCUT_STYLE.md](./ARCHITECTURE_CAPCUT_STYLE.md)** - Ki·∫øn tr√∫c chi ti·∫øt multi-track timeline
2. **[ARCHITECTURE_HUONG2.md](./ARCHITECTURE_HUONG2.md)** - Ki·∫øn tr√∫c ExoPlayer + GL compositing
3. **[REALTIME_PREVIEW_EXPLAINED.md](./REALTIME_PREVIEW_EXPLAINED.md)** - Gi·∫£i th√≠ch real-time preview
4. **[TIMELINE_LAYERS_EXPLAINED.md](./TIMELINE_LAYERS_EXPLAINED.md)** - Gi·∫£i th√≠ch timeline layers theo th·ªùi gian

---

## üéØ T·ªïng Quan H·ªá Th·ªëng

H·ªá th·ªëng video editor ƒëa l·ªõp v·ªõi timeline multi-track, h·ªó tr·ª£:
- ‚úÖ **Mix ·∫£nh + video** trong c√πng timeline
- ‚úÖ **Multi-track**: Video, Overlay, Audio, Text tracks
- ‚úÖ **Keyframe animation**: Transform, opacity, effects theo th·ªùi gian
- ‚úÖ **Rich effects**: Filter, transition, sticker, text v·ªõi animation
- ‚úÖ **Audio mixing**: Background music, sound effects, voice-over
- ‚úÖ **Real-time preview**: Smooth playback v·ªõi effects (30-60fps)
- ‚úÖ **Timeline layers**: M·ªói layer c√≥ startTime/duration ri√™ng
- ‚úÖ **High-quality export**: Multi-pass rendering v·ªõi MediaCodec

---

## üîÑ Lu·ªìng Ho√†n Ch·ªânh: T·ª´ Ch·ªçn Media ‚Üí Preview ‚Üí Export

### Phase 1: User Ch·ªçn ·∫¢nh + Video

#### 1.1. MainActivity - User Click "Create Slideshow"

```kotlin
// MainActivity.kt
buttonStart.setOnClickListener {
    viewModel?.startImagePicker()
}
```

#### 1.2. MainViewModel - Launch Image Picker

```kotlin
// MainViewModel.kt
fun startImagePicker() {
    val currentActivity = activity ?: return
    
    val mediaItems = ArrayList<ImageModel>()
    
    // B∆∞·ªõc 1: Ch·ªçn ·∫£nh (optional, min = 0)
    TedImagePicker.with(currentActivity)
        .image()
        .min(0, "B·∫°n c√≥ th·ªÉ b·ªè qua ch·ªçn ·∫£nh")
        .max(50, "B·∫°n ch·ªâ c√≥ th·ªÉ ch·ªçn t·ªëi ƒëa 50 ·∫£nh")
        .startMultiImage { imageUris ->
            // L∆∞u ·∫£nh ƒë√£ ch·ªçn
            imageUris.forEach { uri ->
                mediaItems.add(ImageModel(uri, isVideo = false))
            }
            
            // B∆∞·ªõc 2: Ch·ªçn video (optional, min = 0)
            TedImagePicker.with(currentActivity)
                .video()
                .min(0, "B·∫°n c√≥ th·ªÉ b·ªè qua ch·ªçn video")
                .max(20, "B·∫°n ch·ªâ c√≥ th·ªÉ ch·ªçn t·ªëi ƒëa 20 video")
                .startMultiImage { videoUris ->
                    // L∆∞u video ƒë√£ ch·ªçn
                    videoUris.forEach { uri ->
                        mediaItems.add(ImageModel(uri, isVideo = true))
                    }
                    
                    // Ki·ªÉm tra c√≥ media n√†o kh√¥ng
                    if (mediaItems.isEmpty()) {
                        Toast.makeText(currentActivity, "Vui l√≤ng ch·ªçn √≠t nh·∫•t 1 ·∫£nh ho·∫∑c video", Toast.LENGTH_SHORT).show()
                        return@startMultiImage
                    }
                    
                    // B∆∞·ªõc 3: Start SlideShowActivity v·ªõi danh s√°ch media
                    val intent = Intent(currentActivity, SlideShowActivity::class.java)
                    intent.putParcelableArrayListExtra(
                        Constant.EXTRA_ARRAY_IMAGE,
                        mediaItems
                    )
                    currentActivity.startActivity(intent)
                }
        }
}
```

**Flow:**
```
User click "Create Slideshow"
    ‚Üì
MainViewModel.startImagePicker()
    ‚Üì
TedImagePicker (Image) ‚Üí User ch·ªçn ·∫£nh
    ‚Üì
TedImagePicker (Video) ‚Üí User ch·ªçn video
    ‚Üì
T·∫°o ArrayList<ImageModel> v·ªõi isVideo flag
    ‚Üì
Start SlideShowActivity v·ªõi intent
```

---

### Phase 2: SlideShowActivity - Initialize Timeline

#### 2.1. SlideShowActivity.onCreate()

```kotlin
// SlideShowActivity.kt
override fun onCreate(savedInstanceState: Bundle?) {
    super.onCreate(savedInstanceState)
    
    // Check audio permission
    checkAndRequestAudioPermission()
    
    // Initialize view
    initView()
    initEvent()
}

private fun initView() {
    // Get media list from intent
    val imageList = if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.TIRAMISU) {
        intent.getParcelableArrayListExtra(Constant.EXTRA_ARRAY_IMAGE, ImageModel::class.java)
    } else {
        @Suppress("DEPRECATION")
        intent.getParcelableArrayListExtra<ImageModel>(Constant.EXTRA_ARRAY_IMAGE)
    }
    
    // Setup ViewModel
    viewModel = ViewModelProviders.of(this).get(SlideShowViewModel::class.java)
    viewModel.setBinding(binding)
    viewModel.initDataBase(this)
    
    // Load media v√†o timeline
    viewModel.loadDataImage(imageList)
    
    // Load other resources
    viewModel.loadTextQuote()
    viewModel.loadDataMusic()
}
```

#### 2.2. SlideShowViewModel.loadDataImage()

```kotlin
// SlideShowViewModel.kt
fun loadDataImage(listImage: ArrayList<ImageModel>?) {
    if (listImage == null || listImage.isEmpty()) {
        Toast.makeText(context, "No media selected", Toast.LENGTH_SHORT).show()
        return
    }
    
    // Convert ImageModel ‚Üí MediaScene ‚Üí Clip
    applyData(listImage)
}

private fun applyData(items: List<ImageModel>) {
    Single.just(items)
        .subscribeOn(Schedulers.io())
        .observeOn(AndroidSchedulers.mainThread())
        .map { inputItems ->
            inputItems.mapIndexed { index, model ->
                createClipFromMedia(model, index)
            }
        }
        .subscribeBy { clips ->
            // Add clips v√†o timeline
            clips.forEach { clip ->
                addClipToTimeline(clip)
            }
            
            // Start preview
            startPreview()
        }
        .willBeDisposed()
}

private fun createClipFromMedia(model: ImageModel, index: Int): Clip {
    return when {
        model.isVideo -> {
            // Video clip
            Clip(
                id = UUID.randomUUID().toString(),
                type = ClipType.VIDEO,
                source = MediaSource(model.uriImage),
                startTime = calculateStartTime(index),  // D·ª±a v√†o clips tr∆∞·ªõc ƒë√≥
                duration = getVideoDuration(model.uriImage),  // T·ª´ MediaMetadataRetriever
                speed = 1.0f
            )
        }
        else -> {
            // Image clip
            Clip(
                id = UUID.randomUUID().toString(),
                type = ClipType.IMAGE,
                source = MediaSource(model.uriImage),
                startTime = calculateStartTime(index),
                duration = 3000L,  // Default 3s cho ·∫£nh
                speed = 1.0f
            )
        }
    }
}

private fun addClipToTimeline(clip: Clip) {
    val track = when (clip.type) {
        ClipType.VIDEO, ClipType.IMAGE -> {
            timelineController.getTrack(TrackType.VIDEO) 
                ?: timelineController.addTrack(TrackType.VIDEO)
        }
        ClipType.AUDIO -> {
            timelineController.getTrack(TrackType.AUDIO)
                ?: timelineController.addTrack(TrackType.AUDIO)
        }
        // ... other types
    }
    
    track.addClip(clip)
    
    // Setup media source (ExoPlayer cho video, Bitmap cho image)
    when (clip.type) {
        ClipType.VIDEO -> mediaSourceManager.setupVideoClip(clip)
        ClipType.IMAGE -> mediaSourceManager.loadImage(clip.source)
        // ...
    }
}
```

**Flow:**
```
SlideShowActivity.onCreate()
    ‚Üì
Get ArrayList<ImageModel> from intent
    ‚Üì
SlideShowViewModel.loadDataImage()
    ‚Üì
For each ImageModel:
    ‚îú‚îÄ isVideo = true ‚Üí Create Video Clip
    ‚îî‚îÄ isVideo = false ‚Üí Create Image Clip
    ‚Üì
Add clips to TimelineController
    ‚Üì
Setup media sources:
    ‚îú‚îÄ Video ‚Üí ExoPlayer + SurfaceTexture
    ‚îî‚îÄ Image ‚Üí Load Bitmap
    ‚Üì
Timeline ready!
```

---

### Phase 3: Setup Rendering Pipeline

#### 3.1. Initialize Compositor

```kotlin
// SlideShowViewModel.kt
fun initDataBase(context: SlideShowActivity) {
    this.context = context
    
    // Initialize compositor
    mediaCompositor = MultiLayerCompositor(
        context = context,
        glContext = eglContext,
        timelineController = timelineController,
        mediaSourceManager = mediaSourceManager
    )
    
    // Setup TextureView for preview
    setupTextureView()
    
    // Initialize other components
    initViewMenuBar()
    initTransitions()
    initFilters()
    // ...
}

private fun setupTextureView() {
    binding.textureView.surfaceTextureListener = object : TextureView.SurfaceTextureListener {
        override fun onSurfaceTextureAvailable(
            surface: SurfaceTexture,
            width: Int,
            height: Int
        ) {
            // Initialize GL context
            val eglContext = EGL14.eglGetCurrentContext()
            
            // Setup compositor v·ªõi surface
            mediaCompositor.setupSurface(surface, width, height)
            
            // Start preview render loop
            startPreview()
        }
        
        // ... other callbacks
    }
}
```

#### 3.2. Start Preview Render Loop

```kotlin
// SlideShowViewModel.kt
private fun startPreview() {
    previewRenderer = PreviewRenderer(
        compositor = mediaCompositor,
        timelineController = timelineController,
        textureView = binding.textureView
    )
    
    previewRenderer.start()
}

// PreviewRenderer.kt
class PreviewRenderer(
    private val compositor: MultiLayerCompositor,
    private val timelineController: TimelineController,
    private val textureView: TextureView
) {
    private val handler = Handler(Looper.getMainLooper())
    private var isPlaying = false
    private var currentTime = 0L
    private val fps = 30
    private val frameInterval = 1000L / fps  // 33ms
    
    fun start() {
        isPlaying = true
        renderLoop()
    }
    
    fun pause() {
        isPlaying = false
    }
    
    fun seekTo(time: Long) {
        currentTime = time
        renderFrame(time)  // Render ngay frame n√†y
    }
    
    private fun renderLoop() {
        if (!isPlaying) return
        
        // Render frame t·∫°i th·ªùi ƒëi·ªÉm hi·ªán t·∫°i
        renderFrame(currentTime)
        
        // Update time
        currentTime += frameInterval
        
        // Loop back n·∫øu h·∫øt timeline
        if (currentTime >= timelineController.totalDuration) {
            currentTime = 0L
        }
        
        // Schedule next frame
        handler.postDelayed({ renderLoop() }, frameInterval)
    }
    
    private fun renderFrame(time: Long) {
        // Query clips t·∫°i th·ªùi ƒëi·ªÉm n√†y
        val clipsAtTime = timelineController.getClipsAtTime(time)
        
        // Render v·ªõi compositor
        val outputTexture = compositor.renderFrame(time, clipsAtTime)
        
        // Update TextureView
        textureView.setSurfaceTexture(outputTexture)
    }
}
```

**Flow:**
```
SlideShowViewModel.initDataBase()
    ‚Üì
Create MultiLayerCompositor
    ‚Üì
Setup TextureView
    ‚Üì
onSurfaceTextureAvailable()
    ‚Üì
Initialize GL context
    ‚Üì
Start PreviewRenderer
    ‚Üì
Render loop ch·∫°y li√™n t·ª•c (30fps)
    ‚Üì
M·ªói frame:
    ‚îú‚îÄ Query clips t·∫°i th·ªùi ƒëi·ªÉm hi·ªán t·∫°i
    ‚îú‚îÄ Render v·ªõi compositor
    ‚îî‚îÄ Update TextureView
```

---

### Phase 4: Render Frame (Chi Ti·∫øt)

#### 4.1. MultiLayerCompositor.renderFrame()

```kotlin
// MultiLayerCompositor.kt
fun renderFrame(time: Long, clipsAtTime: Map<TrackType, List<Clip>>): Texture2d {
    // === STEP 1: Render Video/Image Track (Base Layer) ===
    val videoClips = clipsAtTime[TrackType.VIDEO] ?: emptyList()
    val baseTexture = renderVideoTrack(videoClips, time)
    
    // === STEP 2: Apply Filters ===
    val filteredTexture = applyFilters(baseTexture, videoClips, time)
    
    // === STEP 3: Apply Transforms ===
    val transformedTexture = applyTransforms(filteredTexture, videoClips, time)
    
    // === STEP 4: Render Overlay Track ===
    val overlayClips = clipsAtTime[TrackType.OVERLAY] ?: emptyList()
    val withOverlayTexture = renderOverlayTrack(transformedTexture, overlayClips, time)
    
    // === STEP 5: Render Text Track ===
    val textClips = clipsAtTime[TrackType.TEXT] ?: emptyList()
    val withTextTexture = renderTextTrack(withOverlayTexture, textClips, time)
    
    // === STEP 6: Mix Audio ===
    val audioClips = clipsAtTime[TrackType.AUDIO] ?: emptyList()
    audioMixer.mixAudio(audioClips, time)
    
    return withTextTexture
}

private fun renderVideoTrack(clips: List<Clip>, time: Long): Texture2d {
    if (clips.isEmpty()) return emptyTexture
    
    val clip = clips.first()  // L·∫•y clip ƒë·∫ßu ti√™n (c√≥ th·ªÉ c√≥ nhi·ªÅu clip overlap)
    
    return when (clip.type) {
        ClipType.VIDEO -> {
            // Update ExoPlayer texture
            mediaSourceManager.updateVideoTexture(clip, time)
            mediaSourceManager.getVideoTexture(clip.id)
        }
        ClipType.IMAGE -> {
            // Load image texture
            val bitmap = mediaSourceManager.loadImage(clip.source)
            bitmapToTexture(bitmap)
        }
        else -> emptyTexture
    }
}

private fun applyFilters(texture: Texture2d, clips: List<Clip>, time: Long): Texture2d {
    val clip = clips.firstOrNull() ?: return texture
    val filter = clip.filter ?: return texture
    
    filterShader.use {
        filterShader.setTexture(texture)
        filterShader.setFilter(filter)
        return filterShader.render()
    }
}

private fun applyTransforms(texture: Texture2d, clips: List<Clip>, time: Long): Texture2d {
    val clip = clips.firstOrNull() ?: return texture
    
    // Calculate transform v·ªõi keyframes
    val transform = calculateTransformAtTime(clip, time)
    
    transformShader.use {
        transformShader.setTexture(texture)
        transformShader.setTransform(transform)
        transformShader.setOpacity(transform.opacity)
        return transformShader.render()
    }
}

private fun renderOverlayTrack(baseTexture: Texture2d, overlayClips: List<Clip>, time: Long): Texture2d {
    var resultTexture = baseTexture
    
    // Sort by z-index
    overlayClips.sortedBy { it.transform.zIndex }.forEach { overlayClip ->
        val overlayTexture = getTextureForClip(overlayClip, time)
        
        blendShader.use {
            blendShader.setSourceTexture(overlayTexture)
            blendShader.setDestinationTexture(resultTexture)
            blendShader.setBlendMode(BlendMode.NORMAL)
            blendShader.setOpacity(overlayClip.transform.opacity)
            resultTexture = blendShader.render()
        }
    }
    
    return resultTexture
}

private fun renderTextTrack(baseTexture: Texture2d, textClips: List<Clip>, time: Long): Texture2d {
    var resultTexture = baseTexture
    
    textClips.forEach { textClip ->
        // Render text th√†nh bitmap/texture
        val textTexture = renderTextToTexture(textClip, time)
        
        blendShader.use {
            blendShader.setSourceTexture(textTexture)
            blendShader.setDestinationTexture(resultTexture)
            resultTexture = blendShader.render()
        }
    }
    
    return resultTexture
}
```

**Flow chi ti·∫øt m·ªói frame:**
```
Render Frame t·∫°i time = T
    ‚Üì
Query clips t·∫°i T:
    ‚îú‚îÄ VIDEO track: [clip1 (0-10s)] ‚úÖ
    ‚îú‚îÄ AUDIO track: [music1 (0-10s)] ‚úÖ
    ‚îú‚îÄ OVERLAY track: [frame1 (5-20s)] ‚úÖ
    ‚îî‚îÄ TEXT track: [text1 (8-12s)] ‚úÖ
    ‚Üì
STEP 1: Render Video Track
    ‚îú‚îÄ clip1 l√† VIDEO ‚Üí Update ExoPlayer texture
    ‚îî‚îÄ Get video texture
    ‚Üì
STEP 2: Apply Filter
    ‚îú‚îÄ clip1.filter = Vivid
    ‚îî‚îÄ Apply filter shader
    ‚Üì
STEP 3: Apply Transform
    ‚îú‚îÄ Calculate transform v·ªõi keyframes
    ‚îî‚îÄ Apply transform shader
    ‚Üì
STEP 4: Render Overlay
    ‚îú‚îÄ frame1 (5-20s) ƒëang active
    ‚îî‚îÄ Blend overlay texture
    ‚Üì
STEP 5: Render Text
    ‚îú‚îÄ text1 (8-12s) ƒëang active
    ‚îî‚îÄ Blend text texture
    ‚Üì
STEP 6: Mix Audio
    ‚îú‚îÄ music1 (0-10s) ƒëang active
    ‚îî‚îÄ Play audio
    ‚Üì
Output texture ‚Üí TextureView
```

---

### Phase 5: User Apply Effects (Real-time Preview)

#### 5.1. User Click "Apply Filter"

```kotlin
// SlideShowViewModel.kt
fun applyFilterToClip(clipId: String, filterId: String) {
    // T√¨m clip trong timeline
    val clip = timelineController.findClip(clipId) ?: return
    
    // Update filter property
    clip.filter = FilterLibrary.getFilter(filterId)
    
    // ‚úÖ Preview ngay l·∫≠p t·ª©c!
    // Render loop s·∫Ω t·ª± ƒë·ªông pick up change ·ªü frame ti·∫øp theo
    // Kh√¥ng c·∫ßn g·ªçi render() th·ªß c√¥ng
}
```

#### 5.2. User Add Overlay Layer

```kotlin
// SlideShowViewModel.kt
fun addOverlayLayer(overlayUri: Uri, startTime: Long, duration: Long) {
    val overlayClip = Clip(
        type = ClipType.EFFECT_OVERLAY,
        source = MediaSource(overlayUri),
        startTime = startTime,
        duration = duration
    )
    
    // Load texture
    overlayClip.texture = loadOverlayTexture(overlayUri)
    
    // Add to overlay track
    timelineController.getTrack(TrackType.OVERLAY)?.addClip(overlayClip)
    
    // ‚úÖ Preview ngay! Overlay s·∫Ω xu·∫•t hi·ªán ·ªü frame ti·∫øp theo
}
```

#### 5.3. User Add Audio Layer

```kotlin
// SlideShowViewModel.kt
fun addAudioLayer(audioUri: Uri, startTime: Long, duration: Long) {
    val audioClip = Clip(
        type = ClipType.AUDIO,
        source = MediaSource(audioUri),
        startTime = startTime,
        duration = duration,
        volume = 0.8f
    )
    
    // Setup ExoPlayer cho audio
    mediaSourceManager.setupAudioClip(audioClip)
    
    // Add to audio track
    timelineController.getTrack(TrackType.AUDIO)?.addClip(audioClip)
    
    // ‚úÖ Preview ngay! Audio s·∫Ω play ·ªü frame ti·∫øp theo
}
```

**Flow khi apply effect:**
```
User action (click button, drag, etc.)
    ‚Üì
Update clip property (filter, transform, etc.)
    ‚Üì
Clip data updated (ch·ªâ data, kh√¥ng render)
    ‚Üì
Render loop (ƒëang ch·∫°y):
    Frame N: Render v·ªõi data c≈©
    Frame N+1 (33ms sau):
        ‚Üí Query clips ‚Üí ƒê·ªçc property m·ªõi
        ‚Üí Render v·ªõi effect m·ªõi
    ‚Üì
Screen: Preview ngay l·∫≠p t·ª©c! ‚úÖ
```

---

### Phase 6: Export Video

#### 6.1. User Click "Export"

```kotlin
// SlideShowViewModel.kt
fun exportVideo() {
    SaveVideoBottomSheet
        .newInstance()
        .show(context.supportFragmentManager, "save_video")
}

// SaveVideoBottomSheet callback
fun onExportConfirmed(width: Int, height: Int, quality: ExportQuality) {
    viewModel.exportVideo(width, height, quality)
}

fun exportVideo(width: Int, height: Int, quality: ExportQuality) {
    isExport.value = true
    
    // Setup exporter
    val exporter = VideoExporter(
        context = context,
        timelineController = timelineController,
        compositor = mediaCompositor,
        audioMixer = audioMixer
    )
    
    // Export v·ªõi progress callback
    exporter.export(
        outputPath = getOutputPath(),
        width = width,
        height = height,
        fps = 30,
        bitrate = quality.bitrate,
        onProgress = { progress ->
            // Update UI
            binding.progressBarExport.progress = (progress * 100).toInt()
            binding.textViewMessageExport.text = "Exporting (${(progress * 100).toInt()}%)"
        }
    ) { outputPath ->
        // Export completed
        isExport.value = false
        Toast.makeText(context, "Video exported: $outputPath", Toast.LENGTH_SHORT).show()
    }
}
```

#### 6.2. VideoExporter.export()

```kotlin
// VideoExporter.kt
fun export(
    outputPath: String,
    width: Int,
    height: Int,
    fps: Int,
    bitrate: Int,
    onProgress: (Float) -> Unit,
    onComplete: (String) -> Unit
) {
    val totalDuration = timelineController.totalDuration
    val frameCount = (totalDuration / 1000f * fps).toInt()
    
    // Setup encoders
    val videoEncoder = setupVideoEncoder(width, height, fps, bitrate)
    val audioEncoder = setupAudioEncoder()
    val muxer = MediaMuxer(outputPath, MediaMuxer.OutputFormat.MUXER_OUTPUT_MP4_2)
    
    var videoTrackIndex = -1
    var audioTrackIndex = -1
    
    // Render and encode each frame
    for (frameIndex in 0 until frameCount) {
        val time = (frameIndex * 1000L / fps)
        val progress = frameIndex.toFloat() / frameCount
        onProgress(progress)
        
        // === Render frame (gi·ªëng preview nh∆∞ng full quality) ===
        val clipsAtTime = timelineController.getClipsAtTime(time)
        val frameTexture = compositor.renderFrame(time, clipsAtTime, quality = 1.0f)
        
        // === Encode video frame ===
        encodeVideoFrame(videoEncoder, frameTexture, frameIndex, fps)
        
        // === Encode audio (m·ªói gi√¢y m·ªôt l·∫ßn) ===
        if (frameIndex % fps == 0) {
            val audioBuffer = audioMixer.prepareAudio(time, 1000L)
            encodeAudioFrame(audioEncoder, audioBuffer)
        }
    }
    
    // Finish encoding
    finishEncoding(videoEncoder, audioEncoder, muxer)
    
    onComplete(outputPath)
}
```

**Flow export:**
```
User click "Export"
    ‚Üì
Show quality options (720p, 1080p, 4K)
    ‚Üì
User ch·ªçn quality
    ‚Üì
VideoExporter.export()
    ‚Üì
Setup MediaCodec encoders:
    ‚îú‚îÄ Video encoder (H.264)
    ‚îî‚îÄ Audio encoder (AAC)
    ‚Üì
For each frame (0 ‚Üí totalDuration):
    ‚îú‚îÄ Render frame v·ªõi full quality
    ‚îú‚îÄ Encode video frame
    ‚îî‚îÄ Encode audio (m·ªói gi√¢y)
    ‚Üì
MediaMuxer combine video + audio
    ‚Üì
Save MP4 file
    ‚Üì
Show completion message
```

---

## üìä Timeline Example: Chi Ti·∫øt

### Scenario: Video 30s v·ªõi nhi·ªÅu layers

```
Time:    0s    5s    10s   15s   20s   25s   30s
        |-----|-----|-----|-----|-----|-----|
VIDEO:  [====================================]
        Main video clip (0-30s)
        |-----|-----|-----|-----|-----|-----|
AUDIO:  [========]     [====================]
        Music 1 (0-10s)  Music 2 (15-30s)
        [==] (sfx 5-7s)
        |-----|-----|-----|-----|-----|-----|
OVERLAY:     [===============]
             Frame overlay (5-20s)
             [=======================]
             Vignette (10-25s)
        |-----|-----|-----|-----|-----|-----|
TEXT:   [====]
        Title (0-5s)
        [====]
        Subtitle (8-12s)
        |-----|-----|-----|-----|-----|-----|
STICKER:            [==========]
                    Sticker 1 (15-25s)
                    [========]
                    Sticker 2 (20-28s)
```

### Render t·∫°i c√°c th·ªùi ƒëi·ªÉm:

**T·∫°i 0s:**
- ‚úÖ Video clip
- ‚úÖ Music 1
- ‚úÖ Title text

**T·∫°i 7s:**
- ‚úÖ Video clip
- ‚úÖ Music 1
- ‚úÖ Frame overlay
- ‚úÖ Subtitle text

**T·∫°i 18s:**
- ‚úÖ Video clip
- ‚úÖ Music 2
- ‚úÖ Frame overlay
- ‚úÖ Vignette
- ‚úÖ Sticker 1

**T·∫°i 25s:**
- ‚úÖ Video clip
- ‚úÖ Music 2
- ‚úÖ Sticker 2

---

## üéØ Key Components Summary

### 1. TimelineController
- Qu·∫£n l√Ω multi-track timeline
- Query clips t·∫°i th·ªùi ƒëi·ªÉm c·ª• th·ªÉ
- T√≠nh to√°n duration, progress

### 2. MediaSourceManager
- Qu·∫£n l√Ω ExoPlayer pool cho video
- Load v√† cache images
- Setup audio players

### 3. MultiLayerCompositor
- Render pipeline ch√≠nh
- Apply filters, transforms, overlays
- Output texture cho preview/export

### 4. PreviewRenderer
- Render loop (30-60fps)
- Sync v·ªõi timeline
- Update TextureView

### 5. VideoExporter
- Encode frames v·ªõi MediaCodec
- Mix audio
- Mux th√†nh MP4

---

## ‚úÖ Checklist Implementation

### Phase 1: Core Timeline ‚úÖ
- [x] TimelineController
- [x] Track & Clip data structures
- [x] Query clips t·∫°i th·ªùi ƒëi·ªÉm

### Phase 2: Media Playback ‚úÖ
- [x] ExoPlayer integration
- [x] Video texture management
- [x] Image loading & caching

### Phase 3: Rendering Pipeline ‚úÖ
- [x] MultiLayerCompositor
- [x] Filter system
- [x] Transform system
- [x] Overlay blending

### Phase 4: Real-time Preview ‚úÖ
- [x] PreviewRenderer
- [x] Render loop
- [x] TextureView integration

### Phase 5: Effects System ‚úÖ
- [x] Filter library
- [x] Transition library
- [x] Keyframe animation
- [x] Timeline layers

### Phase 6: Export ‚úÖ
- [x] Video encoder
- [x] Audio encoder
- [x] MediaMuxer integration

---

## üìñ References

- [ARCHITECTURE_CAPCUT_STYLE.md](./ARCHITECTURE_CAPCUT_STYLE.md) - Full architecture details
- [REALTIME_PREVIEW_EXPLAINED.md](./REALTIME_PREVIEW_EXPLAINED.md) - Preview mechanism
- [TIMELINE_LAYERS_EXPLAINED.md](./TIMELINE_LAYERS_EXPLAINED.md) - Timeline layers

---

## üöÄ Next Steps

1. **Implement Phase 1-2**: Core timeline + media playback
2. **Test v·ªõi 1 video + 1 image**: Verify basic flow
3. **Add effects**: Filter, overlay, text
4. **Optimize performance**: Shader caching, texture pooling
5. **Polish UI**: Timeline view, effect picker

